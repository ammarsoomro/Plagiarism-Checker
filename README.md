Key Components
Text Preprocessing:

Tokenization: The text is split into individual words or tokens.
Lemmatization: Words are reduced to their base or root form to ensure that different forms of a word are treated as the same.
Stop Word Removal: Common words that do not contribute significant meaning (e.g., "the," "and") are removed from the text.
Feature Extraction:

The tool uses the TF-IDF (Term Frequency-Inverse Document Frequency) method to convert the preprocessed text into numerical vectors. This representation captures.
